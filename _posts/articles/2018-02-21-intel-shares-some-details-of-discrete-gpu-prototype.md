---
layout: post
title: Intel Shares some details of discrete GPU Prototype
date: 2018-02-21 11:09
author: nvinside
comments: true
categories: [Discrete GPU, GPU, Intel, Prototype]
---
<a href="https://www.pcgamer.com/intel-shares-details-of-a-discrete-gpu-prototype-in-development/" target="_blank" rel="noopener">PCGamer</a> reports that Intel has shared a few diagrams at ISSCC (IEEE International Solid-State Circuits Conference) in San Francisco which were then shared online by Japanese site <a href="https://pc.watch.impress.co.jp/docs/column/kaigai/1107078.html" target="_blank" rel="noopener">PCWatch </a>and then it founds it's way into the internet. The leaked diagrams show a discrete graphics chip based on Intel's 9th generation graphics architecture, built on a 14 nm process and has around 1.5 billion transistors. The clock speed is 400MHz at 1.2v.

<img class=" size-full wp-image-2960 aligncenter" src="https://chefkochblog.files.wordpress.com/2018/02/60944_01_intel-teases-discrete-gpu-prototype-powered-raja-koduri.png" alt="60944_01_intel-teases-discrete-gpu-prototype-powered-raja-koduri" width="620" height="348" />

<!--more-->

Intel's secret discrete GPU solution is the first discrete GPU the company has worked on since the days of the i740.

<img class="alignnone size-full wp-image-2961" src="https://chefkochblog.files.wordpress.com/2018/02/60944_02_intel-teases-discrete-gpu-prototype-powered-raja-koduri.jpg" alt="60944_02_intel-teases-discrete-gpu-prototype-powered-raja-koduri" width="620" height="348" />

<h2>Specs</h2>

<ul>
    <li>14nm process, packing 1.5 billion transistors - comparing it to the 12.5 billion on AMD's Radeon RX Vega 64 and the 12 billion or NVIDIA's GeForce GTX 1080 Ti</li>
    <li>1,2V with 400 MHz speed</li>
    <li>DIE size 8.0 x 8.0 mm²</li>
    <li>10 Metal Layer</li>
    <li>Tri-Gate High-K/MG design</li>
    <li>The rest could be changed, the prototype is as not the final product</li>
</ul>

<h2>Final Words</h2>

This isn't something that will compete with the Radeon or GeForce line of graphics cards, but a super-powered Intel NUC makes sense. We will see how it performs when there are the first test samples released but I have some hopes that it would be enough to watch HD/4K video-material on a low-efficiency Chip which could be interesting for low-end devices which are only running small applications on the host.

<h2><span style="color:#ff0000;">Update</span></h2>

Intel said that this is not a real prototype.

<blockquote>Last week at ISSCC, Intel Labs presented a research paper exploring new circuit techniques optimized for power management. The team used an existing Intel integrated GPU architecture (Gen 9 GPU) as a proof of concept for these circuit techniques. This is a test vehicle only, not a future product. While we intend to compete in graphics products in the future, this research paper is unrelated. Our goal with this research is to explore possible, future circuit techniques that may improve the power and performance of Intel products</blockquote>
